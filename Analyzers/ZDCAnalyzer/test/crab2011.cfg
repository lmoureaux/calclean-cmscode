# rename file to crab.cfg before usage
[CRAB]

jobtype = cmssw
scheduler = caf
###       or let crab chose one server automatically for you 
#use_server = 1

[CAF]
queue = cmscaf1nd 

[CMSSW]

### The data you want to access (to be found on DBS)
datasetpath=/HIExpressPhysics/HIRun2011-Express-v1/FEVT
runselection=181529-181532
total_number_of_lumis   = -1
lumis_per_job            = 900
#datasetpath=none
# crab: When splitting by lumi section you must specify two and only two of:
#  number_of_jobs, lumis_per_job, total_number_of_lumis

### The ParameterSet you want to use
pset=zdc_2011_CAF_cfg.py

### The output files (comma separated list)
output_file = zdctrees_HIExpress_181529To181352.root

[USER]

### OUTPUT files INTO A SE
copy_data = 1

### if you want to copy data in a "official CMS site"
### you have to specify the name as written in
storage_element = srm-cms.cern.ch
### the user_remote_dir will be created under the SE mountpoint
### in the case of publication this directory is not considered
### make sure the directory has proper permissions
### https://twiki.cern.ch/twiki/bin/view/CMSPublic/SWGuideCrabFaq#4_Stage_out_in_your_own_director
storage_path=/castor/cern.ch
user_remote_dir = user/b/belt/ZDC2011/Nov12



